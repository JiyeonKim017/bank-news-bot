import os
import requests
import yfinance as yf
from datetime import datetime
from collections import Counter
import re

# 1. í™˜ê²½ ë³€ìˆ˜
CLIENT_ID = os.getenv("NAVER_CLIENT_ID")
CLIENT_SECRET = os.getenv("NAVER_CLIENT_SECRET")

# 2. ì–¸ë¡ ì‚¬ ë„ë©”ì¸ ë§¤ì¹­ ì‚¬ì „ (ë³´ë‚´ì£¼ì‹  ê²½ì œì§€ ì¤‘ì‹¬)
MEDIA_MAP = {
    "mk.co.kr": "ë§¤ì¼ê²½ì œ",
    "hankyung.com": "í•œêµ­ê²½ì œ",
    "sedaily.com": "ì„œìš¸ê²½ì œ",
    "mt.co.kr": "ë¨¸ë‹ˆíˆ¬ë°ì´",
    "edaily.co.kr": "ì´ë°ì¼ë¦¬",
    "fnnews.com": "íŒŒì´ë‚¸ì…œë‰´ìŠ¤",
    "bizwatch.co.kr": "ë¹„ì¦ˆì›Œì¹˜",
    "chosunbiz.com": "ì¡°ì„ ë¹„ì¦ˆ",
    "asiae.co.kr": "ì•„ì‹œì•„ê²½ì œ",
    "heraldcorp.com": "í—¤ëŸ´ë“œê²½ì œ",
    "dnews.co.kr": "ëŒ€í•œê²½ì œ",
    "joseilbo.com": "ì¡°ì„¸ì¼ë³´",
    "yna.co.kr": "ì—°í•©ë‰´ìŠ¤",
    "news1.kr": "ë‰´ìŠ¤1",
    "newsis.com": "ë‰´ì‹œìŠ¤"
}

def get_financial_indicators():
    try:
        usd_krw = yf.Ticker("USDKRW=X")
        hist = usd_krw.history(period="2d")
        curr = hist['Close'].iloc[-1]
        diff = curr - hist['Close'].iloc[0]
        diff_str = f"â–² {diff:.2f}" if diff > 0 else f"â–¼ {abs(diff):.2f}"
        kospi = yf.Ticker("^KS11")
        k_val = kospi.history(period="1d")['Close'].iloc[-1]
        return f"{curr:,.2f}", diff_str, f"{k_val:,.2f}"
    except:
        return "ë°ì´í„° í™•ì¸ ë¶ˆê°€", "-", "ë°ì´í„° í™•ì¸ ë¶ˆê°€"

def get_news(query):
    # ìµœì‹ ìˆœ ì •ë ¬
    url = f"https://openapi.naver.com/v1/search/news.json?query={query}&display=50&sort=date"
    headers = {"X-Naver-Client-Id": CLIENT_ID, "X-Naver-Client-Secret": CLIENT_SECRET}
    res = requests.get(url, headers=headers)
    return res.json().get('items', []) if res.status_code == 200 else []

def get_media_name(link):
    """ë§í¬ ì£¼ì†Œì—ì„œ ì–¸ë¡ ì‚¬ ì´ë¦„ì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    for domain, name in MEDIA_MAP.items():
        if domain in link:
            return name
    return "ê¸°íƒ€"

def main():
    now = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    queries = ["ì‹œì¤‘ì€í–‰ ê¸ˆë¦¬", "ì€í–‰ DX", "ê°€ê³„ëŒ€ì¶œ ê·œì œ"]
    
    rate, diff, kospi = get_financial_indicators()
    all_titles, news_section = [], ""

    for q in queries:
        items = get_news(q)
        news_section += f"#### ğŸ” '{q}' ì„¹ì…˜\n| ë‚ ì§œ | ì–¸ë¡ ì‚¬ | ë‰´ìŠ¤ ì œëª© |\n| :--- | :--- | :--- |\n"
        
        unique_titles = set()
        count = 0
        for item in items:
            title = re.sub(r'<[^>]*>', '', item['title']).replace('&quot;', '"').replace('&apos;', "'")
            media = get_media_name(item['link'])
            
            # ì§€ì •í•œ ê²½ì œì§€ ìœ„ì£¼ë¡œ ê°€ì ¸ì˜¤ê³  ì‹¶ë‹¤ë©´ 'ê¸°íƒ€'ë¥¼ ì œì™¸í•˜ë„ë¡ í•„í„°ë§ ê°€ëŠ¥
            # ì—¬ê¸°ì„œëŠ” 'ê¸°íƒ€'ë„ í¬í•¨í•˜ë˜ ìƒìœ„ 5ê°œë§Œ ë…¸ì¶œ
            if title not in unique_titles and count < 5:
                date = item['pubDate'][5:16]
                news_section += f"| {date} | {media} | [{title}]({item['link']}) |\n"
                all_titles.append(title)
                unique_titles.add(title)
                count += 1
        news_section += "\n"

    # íŠ¸ë Œë“œ ë° ê°ì„± ë¶„ì„ ë¡œì§ (ìƒëµ ì—†ì´ í¬í•¨)
    words = []
    for t in all_titles:
        clean = re.sub(r'[^ê°€-í£a-zA-Z\s]', '', t)
        words.extend([w for w in clean.split() if len(w) >= 2])
    trends = [f"`#{tag}`" for tag, _ in Counter(words).most_common(5)]

    readme = f"""# ğŸ¦ ê¸ˆìœµ ë‰´ìŠ¤ íŠ¸ë Œë“œ ëŒ€ì‹œë³´ë“œ

> **ì—…ë°ì´íŠ¸:** `{now}` (KST)

---

### ğŸ”¥ ì˜¤ëŠ˜ì˜ í•µì‹¬ í‚¤ì›Œë“œ
{" ".join(trends)}

---

### ğŸ“ˆ ì£¼ìš” ê²½ì œ ì§€í‘œ
| ì§€í‘œëª… | í˜„ì¬ê°€ | ë³€ë™ |
| :--- | :---: | :---: |
| **USD/KRW í™˜ìœ¨** | {rate}ì› | {diff} |
| **ì½”ìŠ¤í”¼ ì§€ìˆ˜** | {kospi} | - |

---

### ğŸ“° ì„¹ì…˜ë³„ ì‹¤ì‹œê°„ ë‰´ìŠ¤ (ìµœì‹ ìˆœ)
{news_section}

---
*ì œì‘: JiyeonKim017 / ë§¤ì¼ ìë™ ì—…ë°ì´íŠ¸ ì¤‘*
"""
    with open("README.md", "w", encoding="utf-8") as f:
        f.write(readme)

if __name__ == "__main__":
    main()
