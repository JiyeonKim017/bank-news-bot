import os
import requests
import yfinance as yf
from datetime import datetime
from collections import Counter
import re

# 1. í™˜ê²½ ë³€ìˆ˜
CLIENT_ID = os.getenv("NAVER_CLIENT_ID")
CLIENT_SECRET = os.getenv("NAVER_CLIENT_SECRET")

# 2. ë¶„ì„ìš© ë‹¨ì–´ ì„¤ì •
POS_WORDS = ['ìƒìŠ¹', 'ëŒíŒŒ', 'í˜¸ì¬', 'ê¸‰ë“±', 'ìµœê³ ', 'ì„±ì¥', 'í™•ëŒ€', 'ê¸°ëŒ€', 'ê°•ì„¸', 'í‘ì']
NEG_WORDS = ['í•˜ë½', 'ìœ„ê¸°', 'ìš°ë ¤', 'ê¸‰ë½', 'ìµœì €', 'ì¹¨ì²´', 'ì¶•ì†Œ', 'ê°ì†Œ', 'ì•½ì„¸', 'ì ì']

def get_financial_indicators():
    """ì‹¤ì‹œê°„ í™˜ìœ¨ ë° ì½”ìŠ¤í”¼ ì§€ìˆ˜ ìˆ˜ì§‘"""
    try:
        usd_krw = yf.Ticker("USDKRW=X")
        hist = usd_krw.history(period="2d")
        curr = hist['Close'].iloc[-1]
        diff = curr - hist['Close'].iloc[0]
        diff_str = f"â–² {diff:.2f}" if diff > 0 else f"â–¼ {abs(diff):.2f}"
        
        kospi = yf.Ticker("^KS11")
        k_val = kospi.history(period="1d")['Close'].iloc[-1]
        return f"{curr:,.2f}", diff_str, f"{k_val:,.2f}"
    except:
        return "1,345.00", "-", "2,580.00"

def extract_trends(titles):
    """ë‰´ìŠ¤ ì œëª©ì—ì„œ 2ê¸€ì ì´ìƒì˜ ë¹ˆë„ ë†’ì€ ë‹¨ì–´ 5ê°œ ì¶”ì¶œ"""
    words = []
    for title in titles:
        clean = re.sub(r'[^ê°€-í£a-zA-Z\s]', '', title)
        words.extend([w for w in clean.split() if len(w) >= 2])
    common = Counter(words).most_common(5)
    return [f"`#{tag}`" for tag, count in common]

def analyze_sentiment(titles):
    score = sum(1 for t in titles for p in POS_WORDS if p in t) - \
            sum(1 for t in titles for n in NEG_WORDS if n in t)
    if score > 2: return "ê¸ì • ğŸ˜Š", "í˜„ì¬ ì‹œì¥ ë¶„ìœ„ê¸°ëŠ” ë°ì€ í¸ì…ë‹ˆë‹¤."
    if score < -2: return "ì£¼ì˜ âš ï¸", "ë¦¬ìŠ¤í¬ ê´€ë¦¬ì— ìœ ì˜í•´ì•¼ í•  ì‹œì ì…ë‹ˆë‹¤."
    return "ë³´í•© â–", "í‰ì´í•œ íë¦„ì„ ìœ ì§€í•˜ê³  ìˆìŠµë‹ˆë‹¤."

def get_news(query):
    url = f"https://openapi.naver.com/v1/search/news.json?query={query}&display=15&sort=sim"
    headers = {"X-Naver-Client-Id": CLIENT_ID, "X-Naver-Client-Secret": CLIENT_SECRET}
    res = requests.get(url, headers=headers)
    return res.json().get('items', []) if res.status_code == 200 else []

def main():
    now = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    queries = ["ì‹œì¤‘ì€í–‰ ê¸ˆë¦¬", "ì€í–‰ DX", "ê°€ê³„ëŒ€ì¶œ ê·œì œ"]
    
    rate, diff, kospi = get_financial_indicators()
    all_titles, news_section = [], ""

    for q in queries:
        items = get_news(q)
        news_section += f"#### ğŸ” '{q}' ì„¹ì…˜\n| ë‚ ì§œ | ë‰´ìŠ¤ ì œëª© |\n| :--- | :--- |\n"
        for item in items[:5]:
            t = re.sub(r'<[^>]*>', '', item['title']).replace('&quot;', '"').replace('&apos;', "'")
            news_section += f"| {item['pubDate'][5:16]} | [{t}]({item['link']}) |\n"
            all_titles.append(t)
        news_section += "\n"

    trends = extract_trends(all_titles)
    s_label, s_desc = analyze_sentiment(all_titles)

    readme = f"""# ğŸ¦ ê¸ˆìœµ ë‰´ìŠ¤ íŠ¸ë Œë“œ ëŒ€ì‹œë³´ë“œ

> **ì—…ë°ì´íŠ¸:** `{now}` (KST)

---

### ğŸ”¥ ì˜¤ëŠ˜ì˜ í•µì‹¬ í‚¤ì›Œë“œ
{" ".join(trends)}

---

### ğŸ“ˆ ì£¼ìš” ê²½ì œ ì§€í‘œ
| ì§€í‘œëª… | í˜„ì¬ê°€ | ë³€ë™ |
| :--- | :---: | :---: |
| **USD/KRW í™˜ìœ¨** | {rate}ì› | {diff} |
| **ì½”ìŠ¤í”¼ ì§€ìˆ˜** | {kospi} | - |

---

### ğŸ’¡ ì˜¤ëŠ˜ì˜ ì‹œì¥ ë¶„ìœ„ê¸°
> **ì¢…í•© ì˜ê²¬:** `{s_label}`  
> {s_desc}

---

### ğŸ“° ì„¹ì…˜ë³„ ì‹¤ì‹œê°„ ë‰´ìŠ¤
{news_section}

---
*ì œì‘: JiyeonKim017 / ë§¤ì¼ ìë™ ì—…ë°ì´íŠ¸ ì¤‘*
"""
    with open("README.md", "w", encoding="utf-8") as f:
        f.write(readme)

if __name__ == "__main__":
    main()
