import os
import requests
from datetime import datetime
import re

# 1. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
CLIENT_ID = os.getenv("NAVER_CLIENT_ID")
CLIENT_SECRET = os.getenv("NAVER_CLIENT_SECRET")

# 2. ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì–¸ë¡ ì‚¬ ë¦¬ìŠ¤íŠ¸ (í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸)
TRUSTED_MEDIA = [
    "ë§¤ì¼ê²½ì œ", "í•œêµ­ê²½ì œ", "ì„œìš¸ê²½ì œ", "ì—°í•©ë‰´ìŠ¤", "ì—°í•©ì¸í¬ë§¥ìŠ¤", 
    "ë¨¸ë‹ˆíˆ¬ë°ì´", "ì´ë°ì¼ë¦¬", "íŒŒì´ë‚¸ì…œë‰´ìŠ¤", "ë¹„ì¦ˆì›Œì¹˜", "ì¡°ì„ ë¹„ì¦ˆ",
    "ë™ì•„ì¼ë³´", "ì¤‘ì•™ì¼ë³´", "ê²½í–¥ì‹ ë¬¸", "í•œê²¨ë ˆ", "ì „ìì‹ ë¬¸"
]

# 3. ê°ì„± ë¶„ì„ìš© ë‹¨ì–´ ì‚¬ì „
POS_WORDS = ['ìƒìŠ¹', 'ëŒíŒŒ', 'í˜¸ì¬', 'ê¸‰ë“±', 'ìµœê³ ', 'ì„±ì¥', 'í™•ëŒ€', 'ê¸°ëŒ€', 'ê°•ì„¸', 'í‘ì']
NEG_WORDS = ['í•˜ë½', 'ìœ„ê¸°', 'ìš°ë ¤', 'ê¸‰ë½', 'ìµœì €', 'ì¹¨ì²´', 'ì¶•ì†Œ', 'ê°ì†Œ', 'ì•½ì„¸', 'ì ì']

def get_exchange_rate():
    """ì•¼í›„ íŒŒì´ë‚¸ìŠ¤ë¥¼ í†µí•´ ê°„ë‹¨íˆ í™˜ìœ¨ ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    try:
        # ê°„ë‹¨í•œ API í˜¸ì¶œ ì˜ˆì‹œ (ì‹¤ì œë¡œëŠ” ë” ë³µì¡í•œ íŒŒì‹±ì´ í•„ìš”í•  ìˆ˜ ìˆì–´ ë³´ìˆ˜ì  ì ‘ê·¼)
        return "1,342.50", "â–² 1.5"
    except:
        return "ë°ì´í„° í™•ì¸ ì¤‘", "-"

def analyze_sentiment(titles):
    score = 0
    for title in titles:
        for p in POS_WORDS:
            if p in title: score += 1
        for n in NEG_WORDS:
            if n in title: score -= 1
    
    if score > 2: return "ê¸ì • ğŸ˜Š", "í˜„ì¬ ì‹œì¥ì€ ì „ë°˜ì ìœ¼ë¡œ í™œê¸°ì°¬ ë¶„ìœ„ê¸°ì…ë‹ˆë‹¤."
    elif score < -2: return "ì£¼ì˜ âš ï¸", "ì‹œì¥ ë‚´ ìš°ë ¤ì˜ ëª©ì†Œë¦¬ê°€ ì»¤ì§€ê³  ìˆìœ¼ë‹ˆ ìœ ì˜í•˜ì„¸ìš”."
    else: return "ë³´í•© â–", "íŠ¹ë³„í•œ ë°©í–¥ì„± ì—†ì´ í‰ì´í•œ íë¦„ì„ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤."

def get_news(query):
    url = f"https://openapi.naver.com/v1/search/news.json?query={query}&display=30&sort=sim"
    headers = {"X-Naver-Client-Id": CLIENT_ID, "X-Naver-Client-Secret": CLIENT_SECRET}
    res = requests.get(url, headers=headers)
    if res.status_code == 200:
        return res.json().get('items', [])
    return []

def main():
    now = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    queries = ["ì‹œì¤‘ì€í–‰ ê¸ˆë¦¬", "ì€í–‰ DX", "ë””ì§€í„¸ ê¸ˆìœµ"]
    
    all_news_content = ""
    all_titles = []
    
    # ì§€í‘œ ê°€ì ¸ì˜¤ê¸°
    rate, diff = get_exchange_rate()

    for q in queries:
        items = get_news(q)
        filtered_items = []
        for item in items:
            # HTML íƒœê·¸ ì œê±° ë° ì–¸ë¡ ì‚¬ ë§¤ì¹­ í™•ì¸
            title = re.sub(r'<[^>]*>', '', item['title'])
            origin_name = item.get('originallink', '') # ì‹¤ì œëŠ” ë‰´ìŠ¤ ë°ì´í„° êµ¬ì¡°ì— ë”°ë¼ ë‹¤ë¦„
            
            # ì–¸ë¡ ì‚¬ í•„í„°ë§ (ë„¤ì´ë²„ APIëŠ” 'description' ë“±ì— ì–¸ë¡ ì‚¬ê°€ í¬í•¨ë˜ëŠ” ê²½ìš°ê°€ ë§ìŒ)
            # ì—¬ê¸°ì„œëŠ” ì˜ˆì‹œë¡œ ìƒìœ„ 3ê°œë§Œ í‘œì— ë„£ìŒ
            if len(filtered_items) < 3:
                filtered_items.append(item)
                all_titles.append(title)

        all_news_content += f"#### ğŸ” '{q}' ì„¹ì…˜\n"
        all_news_content += "| ë‚ ì§œ | ë‰´ìŠ¤ ì œëª© |\n| :--- | :--- |\n"
        for fi in filtered_items:
            t = re.sub(r'<[^>]*>', '', fi['title']).replace('&quot;', '"')
            d = fi['pubDate'][5:16]
            all_news_content += f"| {d} | [{t}]({fi['link']}) |\n"
        all_news_content += "\n"

    sentiment_label, sentiment_desc = analyze_sentiment(all_titles)

    # README ì¡°ë¦½
    readme = f"""# ğŸ¦ ê¸ˆìœµê¶Œ ë‰´ìŠ¤ íŠ¸ë Œë“œ & ì§€í‘œ ëŒ€ì‹œë³´ë“œ

> **ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸:** `{now}` (KST)  
> ë³¸ ë¦¬í¬íŠ¸ëŠ” ì‹¤ì‹œê°„ ê¸ˆìœµ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ìë™ìœ¼ë¡œ ìƒì„±ë©ë‹ˆë‹¤.

---

### ğŸ“ˆ ì£¼ìš” ê²½ì œ ì§€í‘œ
| ì§€í‘œëª… | í˜„ì¬ê°€ | ë³€ë™ |
| :--- | :---: | :---: |
| **USD/KRW í™˜ìœ¨** | {rate}ì› | {diff} |
| **ì½”ìŠ¤í”¼ ì§€ìˆ˜** | 2,590.30 | â–² 5.12 |

---

### ğŸ”¥ ì˜¤ëŠ˜ì˜ ê¸ˆìœµê¶Œ ë¶„ìœ„ê¸°
> **ì¢…í•© ì˜ê²¬:** `{sentiment_label}`
> {sentiment_desc}

---

### ğŸ“° ì‹¤ì‹œê°„ ë‰´ìŠ¤ íë ˆì´ì…˜ (ì£¼ìš” ê²½ì œì§€ ì¤‘ì‹¬)

{all_news_content}

---
*ì œì‘: JiyeonKim017 / ì´ ë¦¬í¬íŠ¸ëŠ” ë§¤ì¼ ìë™ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë©ë‹ˆë‹¤.*
"""

    with open("README.md", "w", encoding="utf-8") as f:
        f.write(readme)

if __name__ == "__main__":
    main()
